{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2296b8-7934-47c5-9881-d1fec99fcfb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from functools import reduce\n",
    "import json\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d0905d-83f7-4c7b-8d7b-7ee473f78a76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Corpus and dictionary files to use\n",
    "corpus_file = 'democracy_reports_corpus.csv'\n",
    "dictionary_file = 'dimension_dictionary.json'\n",
    "\n",
    "corpus_file_url = \"https://github.com/backdem/democracy-datasets/raw/main/democracy_reports_corpus.csv\"\n",
    "dictionary_file_url = \"https://raw.githubusercontent.com/backdem/democracy-datasets/main/dimension_dictionary.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d3d61-4a85-4bf6-a8fa-47c15e1d7995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download datsets if not already downloaded\n",
    "if not os.path.exists(corpus_file):\n",
    "    urllib.request.urlretrieve(corpus_file_url, corpus_file)\n",
    "if not os.path.exists(dictionary_file):\n",
    "    urllib.request.urlretrieve(dictionary_file_url, dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0807f-114b-495c-bf6b-83bae17b8ae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data setof all countries, years and sources\n",
    "all_countries_data = pd.read_csv(corpus_file, dtype={'year': str}, comment='#')\n",
    "# calculate sentence lengths\n",
    "all_countries_data[\"sentence_len\"] = all_countries_data[\"sentence\"].apply(lambda x: len(x.split()))\n",
    "# cast sentence column to string\n",
    "all_countries_data['sentence'] = all_countries_data['sentence'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56986c-094a-4c6d-92c7-0385cb20a2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list all countries in the corpus and choose one to process\n",
    "countries =  pd.Series(all_countries_data['country']).unique()\n",
    "print(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e92f6-a7e6-4971-af6b-52f08129f78c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose a country\n",
    "country = [\"france\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd3ff72-2293-4f83-a3d9-2e8b8599a5fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_countries_data)\n",
    "country_data = df[(df['country'].isin(country))]\n",
    "# reset index; needed for proper parsing by BERT\n",
    "country_data = country_data.reset_index(drop=True)\n",
    "corpus_size = len(country_data)\n",
    "number_of_words = reduce(lambda x, y: x + y, country_data[\"sentence_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a7871-a36a-47c4-a1c0-f4ee00a26e4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show length of corpus\n",
    "print(f\"corpus size is {corpus_size} sentences.\")\n",
    "print(f\"total number of words is  {number_of_words}.\")\n",
    "# show first 10 sentences\n",
    "print(country_data.iloc[:10]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eaad50-7304-4da7-adc0-f261b57017c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load dictionary of topics\n",
    "# strcuture [{\"name\": TOPIC_NAME, \"words\": NGRAMS_OF_KEYWORDS}, ...]\n",
    "dictionary = None\n",
    "with open(dictionary_file, 'r') as file:\n",
    "     dictionary = json.load(file)\n",
    "    \n",
    "def get_seed_lists(dictionary, ngram_size):\n",
    "    # create list of topics wit max ngram_size\n",
    "    seeds = []\n",
    "    for topic in dictionary:\n",
    "        seed = [w for w in topic[\"words\"] if len(w.split()) <= ngram_size]\n",
    "        seeds.append(seed)\n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352dfb03-6e69-4d47-ad87-f0b29bbf196f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create seed list from dictionary\n",
    "seeds = get_seed_lists(dictionary, 1)\n",
    "print(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed759448-d7c0-44f3-b2d4-114466287dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "docs = country_data.sentence\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Use KeyBERTInspired representation model. \n",
    "# This gives better names to the topics.\n",
    "representation_model = KeyBERTInspired()\n",
    "embeddings = sentence_model.encode(docs, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d1108-e398-479c-a5da-b22fd734e713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load BERT model paraphrase-MiniLM-L3-v2 (multilingual) or all-MiniLM-L6-v2 (english)\n",
    "# setting min_topic_size to 7 and n_grams from 1 to 3\n",
    "# we need to explore these parameters. Other parameters:\n",
    "# https://maartengr.github.io/BERTopic/getting_started/parameter%20tuning/parametertuning.html\n",
    "# guided topic modeling: https://maartengr.github.io/BERTopic/getting_started/guided/guided.html\n",
    "# seed_topic_list = [[\"corruption\"],\n",
    "#                   [\"elections\", \"election\", \"assembly\"],\n",
    "#                  [\"freedom\", \"liberty\"]]\n",
    "seed_topic_list = get_seed_lists(dictionary, 3)\n",
    "topic_model = BERTopic(representation_model=representation_model, \n",
    "                       seed_topic_list=seed_topic_list, \n",
    "                       verbose=True, \n",
    "                       embedding_model='all-MiniLM-L6-v2', \n",
    "                       min_topic_size = 50, \n",
    "                       n_gram_range=(1, 3)\n",
    "                      ).fit(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a3255-4572-482f-a7ae-8254d3ea49c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_model.visualize_documents(docs, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc954a-bf23-4664-93e7-42c97bbe3767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get topic information\n",
    "info = topic_model.get_topic_info()\n",
    "# normalize counts\n",
    "info[\"norm_count\"] = info[\"Count\"].apply(lambda x: x / corpus_size)\n",
    "# print topic information\n",
    "print(f\"Number of topics: {len(info)}\")\n",
    "print(info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d31051-4232-4bce-b3a6-8dd2905cd655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize topic words/n_grams\n",
    "fig = topic_model.visualize_barchart(top_n_topics=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b60843-ec6b-43e8-af9b-bd4f516cb09a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f9407c-6688-4102-a065-d6dee9f6c521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize topic clusters\n",
    "topic_model.visualize_hierarchy(top_n_topics=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee8b352-cddc-43f4-924c-08867be5ce40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search topics close to our categories\n",
    "dimensions = []\n",
    "for cat in dictionary:\n",
    "    print(f'Closest topic to category: {cat[\"name\"]}.')\n",
    "    topics = cat[\"words\"]\n",
    "    max_similarity = 0\n",
    "    \n",
    "    for topic in topics:\n",
    "        similar_topics, similarities = topic_model.find_topics(topic, top_n = 1)\n",
    "        # most_similar = similar_topics[0]\n",
    "        if similarities[0] > max_similarity:\n",
    "            max_similarity = similarities[0]\n",
    "            most_similar = similar_topics[0]\n",
    "            best_topic = topic\n",
    "    info = topic_model.get_topic_info(most_similar)\n",
    "    # add normalized counts\n",
    "    normalized_count = info[\"Count\"][0] / corpus_size\n",
    "    record = []\n",
    "    record.append(cat[\"name\"])\n",
    "    record.append(most_similar)\n",
    "    record.append(info[\"Name\"][0])\n",
    "    record.append(best_topic)\n",
    "    record.append(max_similarity)\n",
    "    record.append(normalized_count)\n",
    "    record.append(topic_model.get_topic(most_similar))\n",
    "    \n",
    "    \n",
    "    dimensions.append(record)\n",
    "\n",
    "    print(f\"Most Similar Topic Info: {topic_model.get_topic(most_similar)}\")\n",
    "    print(f\"Most Similar Topic Number: {most_similar}\")\n",
    "    print(f\"Best seed match: {best_topic}\")\n",
    "    print(f\"Similarity Score: {max_similarity}\")\n",
    "    print(f\"Topic normalized count: {normalized_count}\")\n",
    "    print(f\"Topic info: {topic_model.get_topic_info(most_similar)}\")\n",
    "    print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b83a39-47e6-4dcc-91d3-9e0cc75be72c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_folder = \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81a6826-a39f-4a4e-a7b0-bc595f7496d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write csv\n",
    "file_name = country[0] + \"_\" + year + \"_dimenstions.csv\"\n",
    "with open(os.path.join(result_folder, file_name), mode=\"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"Dimension\", \"Topic_No\", \"Topic_Name\",  \"Best_Dict_Word_Match\", \"Similarity\", \"Normalized_Count\", \"Topic_Words\"])\n",
    "    for row in dimensions:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe4e0e-e2e4-4d4f-948c-187aa1af24dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get document info\n",
    "doc_info = topic_model.get_document_info(country_data.sentence)\n",
    "# write csv\n",
    "file_name = country[0] + \"_\" + year + \"_sentences.csv\"\n",
    "with open(os.path.join(result_folder, file_name), mode=\"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"Sentence\", \"Topic_Name\", \"Topic_No\", \"Probability\"])\n",
    "    for document, topic, name, top_n_words, prob in zip(doc_info[\"Document\"], doc_info[\"Topic\"], doc_info[\"Name\"], doc_info[\"Top_n_words\"], doc_info[\"Probability\"]):\n",
    "        writer.writerow([document, name, topic, prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc91f3e7-b4da-4403-82bf-6b2d8e9426ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save topic information\n",
    "info = topic_model.get_topic_info()\n",
    "file_name = country[0] + \"_\" + year + \"_topics.csv\"\n",
    "with open(os.path.join(result_folder, file_name), mode=\"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"Topic_No\", \"Topic_Name\", \"Count\", \"Topic_Words\"])\n",
    "    for row in zip(info[\"Topic\"], info[\"Name\"], info[\"Count\"]):\n",
    "        if row[0] == -1:\n",
    "            continue\n",
    "        row = row + (topic_model.get_topic(row[0]),)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220e631d-bdb8-40df-9207-59f928ba3683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "topic_model.save(f\"{result_folder}/{country[0]}_{year}\")\n",
    "\n",
    "# loading model\n",
    "# model=BERTopic.load(\"../data/file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
