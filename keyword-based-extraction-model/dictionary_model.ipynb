{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3bde1eb-5303-4fb0-b9bb-3989238e4632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/reggie/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/reggie/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/reggie/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/reggie/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/reggie/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import csv\n",
    "import plotly.graph_objects as go\n",
    "from generate_count_file import get_keyword_extraction_counts\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2fd066-82a5-40d8-ab2c-1d4425fcbbd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Corpus and dictionary files to use\n",
    "#corpus_file = 'democracy_reports_corpus.csv'\n",
    "corpus_file = '../../data/democracy_reports_corpus_merged_wbacksliding_040724.csv'\n",
    "dictionary_file = 'dimension_dictionary.json'\n",
    "\n",
    "corpus_file_url = \"https://github.com/backdem/democracy-datasets/raw/main/democracy_reports_corpus.csv\"\n",
    "dictionary_file_url = \"https://raw.githubusercontent.com/backdem/democracy-datasets/main/dimension_dictionary.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8023e351-b13e-4c14-9eab-318615bfdbe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download datsets if not already downloaded\n",
    "if not os.path.exists(corpus_file):\n",
    "    urllib.request.urlretrieve(corpus_file_url, corpus_file)\n",
    "if not os.path.exists(dictionary_file):\n",
    "    urllib.request.urlretrieve(dictionary_file_url, dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713f9e89-7d9f-4072-b029-420f532ccf15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reggie/Workspace/backdem/democracy-topic-model/keyword-based-extraction-model/utils.py:66: DtypeWarning: Columns (4,5,6,8,9,10,12,13,14,17,18,19,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_countries_data = pd.read_csv(csv_file, dtype={'year': str}, comment='#')\n"
     ]
    }
   ],
   "source": [
    "# Use CSV file generated from generate_count_file\n",
    "# Generate or import count file\n",
    "df = get_keyword_extraction_counts(corpus_file, dictionary_file, regenerate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857204b8-8bc8-4c30-a3b5-1d865e80064b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print df to see structure\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55106bdc-8209-43d5-a444-dbcd7fd4003c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_stats(data, confidence_level=0.95):\n",
    "    data_mean = np.mean(data)\n",
    "    data_std_dev = np.std(data)\n",
    "    # Calculate the critical value based on the confidence level and a normal distribution\n",
    "    critical_value = stats.norm.ppf((1 + confidence_level) / 2)\n",
    "\n",
    "    # Calculate the standard error of the mean for a population\n",
    "    standard_error = data_std_dev / np.sqrt(len(data))\n",
    "\n",
    "    # Calculate the margin of error\n",
    "    margin_of_error = critical_value * standard_error\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    confidence_interval = (data_mean - margin_of_error, data_mean + margin_of_error)\n",
    "    return (confidence_interval, margin_of_error, data_mean, data_std_dev, critical_value, standard_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4897c0-a885-47a8-8785-9e4190efdeb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_country_dimension_corpus(df, countries=None, title=None):\n",
    "    sub_df = df\n",
    "    # Only plot subset of countries\n",
    "    if countries:\n",
    "        sub_df = df[df['country'].isin(countries)]\n",
    "    \n",
    "    dimensions = pd.Series(sub_df['dimension']).unique()\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for dim in dimensions:\n",
    "        filtered_df = sub_df[sub_df['dimension'] == dim]\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=filtered_df['country'],\n",
    "            x=filtered_df['count'],\n",
    "            name=dim,\n",
    "            orientation='h'\n",
    "        ))   \n",
    "\n",
    "    # Customize the layout (optional)\n",
    "    fig.update_layout(title=title, yaxis_title=None, xaxis_title='counts')\n",
    "\n",
    "    # Display the chart\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89135e-e358-41e9-9e43-1f0d40392ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group by country and dimension\n",
    "df_grouped = pd.DataFrame(df.groupby(['country', 'dimension'])['count'].sum()).reset_index()\n",
    "fig = plot_country_dimension_corpus(df_grouped, title=None)\n",
    "print(df_grouped)\n",
    "# Write pdf image\n",
    "# fig.write_image(\"images/all_countries_counts2.pdf\", width=1024, height=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb85bf48-5477-480f-a391-a3744a6f1ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_country_groups(df, title='Democratic dimensions'):    \n",
    "\n",
    "    west_22 = ['greece', 'italy', 'ireland', 'liechtenstein', 'monaco', 'luxembourg', \n",
    "               'portugal', 'finland', 'austria', 'norway', 'france', 'denmark', \n",
    "               'spain', 'san-marino', 'switzerland', 'sweden', 'germany', 'united-kingdom', \n",
    "               'belgium', 'netherlands', 'iceland', 'andorra', 'denmark']\n",
    "    cee = ['slovenia', 'slovakia', 'latvia', 'poland', 'malta', \n",
    "           'lithuania', 'croatia', 'cyprus', 'hungary', \n",
    "           'estonia', 'romania', 'bulgaria', 'czechia']\n",
    "    eu_candidates = [ 'kosovo', 'moldova','ukraine', 'serbia', \n",
    "                     'north-macedonia', 'turkey', 'bosnia-herzegovina', 'montenegro', \n",
    "                     'albania','georgia']\n",
    "    non_eu = ['armenia', 'azerbaijan', 'belarus', 'russia'] \n",
    "\n",
    "    \n",
    "    group_4 = df[df['country'].isin(non_eu)]            \n",
    "    group_3 = df[df['country'].isin(eu_candidates)]\n",
    "    group_1 = df[df['country'].isin(west_22)]\n",
    "    group_2 = df[df['country'].isin(cee)]\n",
    "    \n",
    "    dimensions = pd.Series(df['dimension']).unique()\n",
    "\n",
    "    groups = [group_1, group_2, group_3, group_4]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    # Create a bar trace for each group\n",
    "    category_names = ['west_eu','cee','eu_candidates', 'non_eu']\n",
    "    traces = []\n",
    "    for dimension in dimensions:    \n",
    "        # Filter the dimension i.e. only get counts per country for a\n",
    "        # single dimension.\n",
    "        grouped_by_dim = [g[g['dimension'] == dimension] for g in groups]  \n",
    "        # Calculate the mean of the counts\n",
    "        mean_counts = [g['count'].mean() for g in grouped_by_dim]       \n",
    "        # Calculate the margin of error of the mean\n",
    "        margin_error = [get_stats(g['count'])[1] for g in grouped_by_dim]\n",
    "        trace = go.Bar(x=category_names,\n",
    "                       y=mean_counts,\n",
    "                       error_y=dict(type='data', array=margin_error, visible=True),\n",
    "                       name=dimension)\n",
    "        traces.append(trace)\n",
    "   \n",
    "    fig = go.Figure(data=traces)\n",
    "\n",
    "    # Update the layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='country groups',\n",
    "        yaxis_title='counts',\n",
    "        barmode='group'  # Set barmode to 'group' to create grouped bars\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "    return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1054dc1f-75cf-4c6c-bc6c-09bb24fea256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plot_country_groups(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86aa0b7-d13c-4b9e-b992-44f84556b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the country grouping but by seperate sources\n",
    "# Get list of sources from data\n",
    "sources = pd.Series(df['source']).unique()\n",
    "df_grouped_source = pd.DataFrame(df.groupby(['country', 'dimension', 'source'])['count'].sum()).reset_index()\n",
    "for source in sources:\n",
    "    df_one_source = df_grouped_source[df_grouped_source['source'] == source]\n",
    "    fig = plot_country_groups(df_one_source, title=f'Democratic dimensions for {source}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46326ba0-a548-4a0e-ae7c-b8c16432a61b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stats imports\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_white, het_breuschpagan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e65c9d-2b65-48b8-98ca-c9d9f90e9085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define linear regression function\n",
    "def linear_regression(df, x_name, y_name):\n",
    "    X = df[[x_name]]\n",
    "    y = df[y_name]\n",
    "   \n",
    "    model = LinearRegression()\n",
    "    model.fit(X,y)\n",
    "    y_pred= model.predict(X)   \n",
    "    return y_pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e6738-a3a0-47a9-8e07-946d762758f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot linear regression model on country corpus size vs keyword hits per dimension\n",
    "def plot_corpus_vs_topic(df, x='count', y='sentence_length', y_pred=[], topic_name='', title=''):\n",
    "    fig = go.Figure()    \n",
    "    fig.add_trace(go.Scatter(x=df[x], y=df[y], name=topic_name, mode='markers', text=df['country']))\n",
    "    # Plot linear regression model is given\n",
    "    if(len(y_pred) > 0):\n",
    "        fig.add_trace(go.Scatter(x=df[x], y=y_pred, name=f'linear fit'))\n",
    "    # Customize the layout (optional)\n",
    "    fig.update_layout(title=title, xaxis_title='corpus size', yaxis_title=f'{topic_name} counts')\n",
    "\n",
    "    # Display the chart\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1921c07d-2c02-4ee4-a85a-5e7f1772cf19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot residuals to check for heteroskedasticity in data set\n",
    "def plot_fitted_vs_residuals(df, y='count', x='sentence_length', topic_name='', title=''):\n",
    "    fig = go.Figure()    \n",
    "    \n",
    "    X = sm.add_constant(df[x])\n",
    "    y = df[y]\n",
    "\n",
    "    model = sm.OLS(y,X).fit()\n",
    "\n",
    "    # Calculate residuals\n",
    "    residuals = y - model.predict(X)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=df[x], y=residuals, name=topic_name, mode='markers+text', text=df['country']))\n",
    "    fig.add_trace(go.Scatter(x=df[x], y=np.zeros(len(residuals)), name=f'predicted'))\n",
    "    # Customize the layout (optional)\n",
    "    fig.update_layout(title=title, xaxis_title='corpus size', yaxis_title=f'{topic_name} residuals')\n",
    "\n",
    "    # Display the chart\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d638fbc-a385-4036-adf4-af9717c3531f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot to residuals in Z-score showing outliers as a Z-score > 2\n",
    "def plot_residuals_zscore(df, x='count', y='sentence_length', topic_name='', title=''):\n",
    "    \n",
    "    fig = go.Figure()    \n",
    "    \n",
    "    X = sm.add_constant(df[x])\n",
    "    y = df[y]\n",
    "\n",
    "    model = sm.OLS(y,X).fit()\n",
    "\n",
    "    # Calculate residuals\n",
    "    residuals = y - model.predict(X)\n",
    "    mean_residuals = np.mean(residuals)\n",
    "    std_residuals = np.std(residuals)\n",
    "    z_score = (residuals - mean_residuals) / (std_residuals)\n",
    "    \n",
    "    outlier_indices = [i for i, y in enumerate(z_score) if abs(y) > 2]\n",
    "    outlier_x = [df[x][i] for i in outlier_indices]\n",
    "    outlier_y = [z_score[i] for i in outlier_indices]\n",
    "    outlier_labels = [df['country'][i] for i in outlier_indices]\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=df[x], y=z_score, name=topic_name, mode='markers', text=df['country']))\n",
    "    fig.add_trace(go.Scatter(x=df[x], y=np.zeros(len(residuals)), name=f'predicted'))\n",
    "    fig.add_trace(go.Scatter(x=outlier_x, y=outlier_y, text=outlier_labels, mode=\"markers+text\", name=\"outliers\"))\n",
    "    \n",
    "    \n",
    "    # Customize the layout (optional)\n",
    "    fig.update_layout(title=title, xaxis_title='corpus size', yaxis_title=f'{topic_name} z_score')\n",
    "    fig.update_traces(selector=dict(name='outliers'), showlegend=False)\n",
    "\n",
    "    # Display the chart\n",
    "    fig.show()\n",
    "    return (fig, df['country'], z_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44554dcb-66c8-486b-b71f-1b23f37b2d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tests for Heteroskedasticity in dataset\n",
    "def breusch_pagan_test(df, x_name, y_name, topic_name='', alpha=0.05):\n",
    "    # Linear regression\n",
    "    X = sm.add_constant(df[x_name])  # Add a constant term for the intercept\n",
    "    y = df[y_name]\n",
    "\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    residuals = model.resid\n",
    "\n",
    "    # White's test\n",
    "    white_test = het_white(residuals, X)\n",
    "    print(\"White's test p-value:\", white_test[1])\n",
    "    if white_test[1] < alpha:\n",
    "        print(\"Heteroskedasticity present\")\n",
    "    else:\n",
    "        print(\"NO heteroskedasticity present\")\n",
    "\n",
    "    # Breusch-Pagan test\n",
    "    bp_test = het_breuschpagan(residuals, X)\n",
    "    print(\"Breusch-Pagan test p-value:\", bp_test[1])\n",
    "    if bp_test[1] < alpha:\n",
    "        print(\"Heteroskedasticity present\")\n",
    "    else:\n",
    "        print(\"NO heteroskedasticity present\")\n",
    "    \n",
    "    # Extract the coefficient of X and its standard error from the model summary\n",
    "    coef_x = model.params[x_name]\n",
    "    std_err_x = model.bse[x_name]\n",
    "\n",
    "    # Calculate the t-statistic for the coefficient of X\n",
    "    t_stat = coef_x / std_err_x\n",
    "\n",
    "    # Calculate the p-value associated with the t-statistic\n",
    "    p_value = model.pvalues[x_name]\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Coefficient of X:\", coef_x)\n",
    "    print(\"Standard error of coefficient of X:\", std_err_x)\n",
    "    print(\"t-statistic:\", t_stat)\n",
    "    print(\"p-value:\", p_value)\n",
    "\n",
    "    if p_value < alpha:\n",
    "        print(f\"Reject the null hypothesis: {x_name} has a significant effect on {topic_name}.\")\n",
    "    else:\n",
    "        print(f\"Fail to reject the null hypothesis: There is not enough evidence to conclude that {x_name} has a significant effect on {topic_name}.\")\n",
    "\n",
    "    return (white_test[1], bp_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d3a242-eaa5-4545-9df4-95ae1b8c8c8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load corpus data to calculate corpus sizes for countries\n",
    "df_corpus = pd.read_csv(corpus_file, dtype={'year': str, 'sentence': str}, comment='#')\n",
    "# Add column with sentence length to corpus\n",
    "df_corpus[\"sentence_length\"] = df_corpus[\"sentence\"].apply(lambda x: len(x.split()))\n",
    "# Calculate corpus size for each country: Group data by country and sum up sentence length\n",
    "df_corpus_country_sizes = pd.DataFrame(df_corpus.groupby(['country'])['sentence_length'].sum()).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96d8932-714e-4cc6-95f1-b597eab11aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot corpus sizes for different countries for all years\n",
    "df_sorted = df_corpus_country_sizes.sort_values(by='sentence_length', ascending=True)\n",
    "fig = go.Figure(data=[go.Bar(x=df_sorted['country'], y=df_sorted['sentence_length'])])\n",
    "\n",
    "# Customize the layout (optional)\n",
    "fig.update_layout(title='Corpus size per country', xaxis_title='Country', yaxis_title='No of Words')\n",
    "\n",
    "# Display the chart\n",
    "fig.show()\n",
    "#fig.write_image(\"images/corpus_size_all_years.pdf\", width=1024, height=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b0de16-50ed-4781-84cc-8ff3d3422d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate dimensions and calculate linear regression for every dimension\n",
    "dimensions = pd.Series(df['dimension']).unique()\n",
    "all_z_scores = {}\n",
    "for dim in dimensions:\n",
    "        print(f\"---PLOTS FOR {dim} DIMENSION---\")\n",
    "        # Filter by dimension\n",
    "        df_dimension = df[df['dimension'] == dim]\n",
    "        df_counts = pd.DataFrame(df_dimension.groupby(['country'])['count'].sum()).reset_index()\n",
    "        # Merge based on the 'key' column\n",
    "        df_merged = pd.merge(df_counts, df_corpus_country_sizes, on='country', how='inner')\n",
    "        y_pred = linear_regression(df_merged, 'sentence_length', 'count')        \n",
    "        fig = plot_corpus_vs_topic(df_merged, x='sentence_length', y='count', y_pred=y_pred, topic_name=dim)\n",
    "        fig = plot_fitted_vs_residuals(df_merged, x='sentence_length', y='count', topic_name=dim)\n",
    "        fig, x, y = plot_residuals_zscore(df_merged, x='sentence_length', y='count', topic_name=dim)\n",
    "        all_z_scores[dim] = (x, y)\n",
    "        breusch_pagan_test(df_merged, x_name=\"count\", y_name='sentence_length', topic_name=dim)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4c25a-b066-46a8-8254-76535f331672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot all z-scores together \n",
    "dimensions = pd.Series(df['dimension']).unique()\n",
    "fig = go.Figure()  \n",
    "for dim in dimensions:\n",
    "    y, x = all_z_scores[dim]    \n",
    "    fig.add_trace(go.Bar(y=y, x=x, orientation='h', name=dim))\n",
    "\n",
    "# Customize the layout (optional)\n",
    "fig.update_layout(title='', yaxis_title='', xaxis_title='z_score normalized residuals', width=1024, height=1024)\n",
    "\n",
    "# Display the chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff5a19-3652-4b63-8294-a181e592d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group counts by year, country, dimension\n",
    "df_grouped_with_years = pd.DataFrame(df.groupby(['dimension', 'year'])['count'].sum()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d4ee8f-e58b-4aea-8765-c2de1cf31b49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot keywords changing over years and dimension\n",
    "def plot_years(df, title=None):\n",
    "    fig = go.Figure()\n",
    "    df = df.sort_values(by='year', ascending=True)\n",
    "    dimensions = pd.Series(df['dimension']).unique()\n",
    "    for dim in dimensions:\n",
    "        df_dim = df[df['dimension'] == dim]\n",
    "        fig.add_trace(go.Scatter(x=df_dim['year'], y=df_dim['count'], name=dim))\n",
    "    \n",
    "    # Customize the layout (optional)\n",
    "    fig.update_layout(title=title, xaxis_title='year', yaxis_title='counts')\n",
    "\n",
    "    # Display the chart\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4971a1f1-915f-4134-b17f-35ac8cbf6ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plot_years(df_grouped_with_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee397dfd-2f8e-455e-8b94-e21c29564b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group counts by year, country, dimension\n",
    "df_grouped_with_sources = pd.DataFrame(df.groupby(['dimension', 'source'])['count'].sum()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf90452a-9057-4b95-9d88-93b4a4e38ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_sources(df, x='source', y='count', title=None):    \n",
    "    \n",
    "    fig = go.Figure()\n",
    "    dimensions = pd.Series(df['dimension']).unique()\n",
    "    for dim in dimensions:\n",
    "        df_dim = df[df['dimension'] == dim]\n",
    "        fig.add_trace(go.Bar(x=df_dim[x], y=df_dim[y], name=dim))\n",
    "    # Customize the layout (optional)\n",
    "    fig.update_layout(title=title, xaxis_title=x, yaxis_title='counts')\n",
    "\n",
    "    # Display the chart\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4b034-3dc4-47cd-8e11-9829e8321f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plot_sources(df_grouped_with_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d0a29-78eb-4982-b573-9e14403c208e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group by dictionary and dimension\n",
    "df_grouped_with_keywords = pd.DataFrame(df.groupby(['dictionary', 'dimension'])['count'].sum()).reset_index()\n",
    "print(df_grouped_with_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e3e55-ef55-4e67-8481-48b2c62cb38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the weight of terms contributing a dimension\n",
    "def plot_terms_in_dimension(df, dimension, title='', plot_logs=False):\n",
    "    fig = go.Figure()\n",
    "    #dimensions = pd.Series(df['dimension']).unique()\n",
    "    #for dim in dimensions:\n",
    "    df_dim = df[df['dimension'] == dimension]\n",
    "    df_dim = df_dim.sort_values(by='count', ascending=False)    \n",
    "    df_dim[\"log_value\"] = df_dim[\"count\"].apply(lambda x: math.log(x))\n",
    "    if plot_logs:\n",
    "        fig.add_trace(go.Bar(x=df_dim['dictionary'], y=df_dim['log_value'], name=dimension))\n",
    "    else:\n",
    "        fig.add_trace(go.Bar(x=df_dim['dictionary'], y=df_dim['count'], name=dimension))\n",
    "    # Customize the layout (optional)\n",
    "    fig.update_layout(title=title, xaxis_title='', yaxis_title='counts', width=1024, height=368)\n",
    "\n",
    "    # Display the chart\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc94a51d-d85e-4a19-baf4-a98951570548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dimensions = pd.Series(df['dimension']).unique()\n",
    "for dim in dimensions:    \n",
    "    print(f\"---PLOT KEYWORDS IN {dim}---\")\n",
    "    fig = plot_terms_in_dimension(df_grouped_with_keywords, dim, plot_logs=False)\n",
    "    fig = plot_terms_in_dimension(df_grouped_with_keywords, dim, plot_logs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
